from konlpy.tag import Okt
from sentence_transformers import SentenceTransformer, util
import torch

# 1. 모델 로딩
print("⏳ AI 모델 로딩 중... (잠시만 기다려주세요)")
okt = Okt()
# 한국어 문장 분석에 특화된 모델 사용
model = SentenceTransformer('jhgan/ko-sroberta-multitask') 
print("✅ AI 모델 로딩 완료!")

# 2. [핵심] 업그레이드된 카테고리 목록
CATEGORIES = [
    # 🚁 IT & 테크 (드론, 컴퓨터 추가!)
    "드론", "영상촬영", "컴퓨터", "조립컴", "전자기기", "얼리어답터", "IT", "코딩", "개발", "장비빨",

    # 💰 재테크 & 명품 (돈, 명품 추가!)
    "재테크", "주식", "부동산", "코인", "투자", "저축", "경제",
    "명품", "쇼핑", "플렉스", "차", "슈퍼카", "시계", "패션", "OOTD",

    # 🏠 주거 & 라이프스타일 (집 관련 추가!)
    "인테리어", "집꾸미기", "자취", "홈스타일링", "가구", "식물", "플랜테리어", "미니멀리즘", "맥시멀리즘",

    # 💄 뷰티 & 관리
    "뷰티", "메이크업", "화장", "코스메틱", "퍼스널컬러", "피부관리", "헤어스타일", "네일아트", "자기관리",

    # 🏫 우리 대학 학과 (전공)
    "간호학과", "보건의료행정과", "바이오생명과", "화장품학과", "스포츠재활과", "글로벌태권도학과",
    "컴퓨터시스템과", "컴퓨터소프트웨어학과", "드론영상과", "바이오테크과",
    "게임아트디자인과", "게임콘텐츠과", "인테리어디자인과", "시각디자인과", "실용음악과", "사진영상미디어과",
    "뷰티스타일리스트과", "약손명가스킨케어과", "사회복지과", "유아교육과",
    "호텔외식조리전공", "베이커리카페전공", "항공서비스과", "호텔관광과", "유통상품기획과", "글로벌관광비즈니스과",
    "푸드테크창업과", "복지케어과", "디지털경영과",

    # 📚 대학 & 자기계발
    "대학생활", "공부", "취업준비", "자기계발", "독서", "자격증", "어학", "창업", "마케팅", "팀플",
    
    # 🎨 여가 & 취미
    "영화", "드라마", "넷플릭스", "웹툰", "애니메이션", "그림", "사진", "글쓰기", "보드게임", "DIY", "전시회",
    
    # 🎮 게임
    "게임", "롤", "발로란트", "배그", "모바일게임", "스팀게임", "유튜브", "SNS",
    
    # ⚽ 운동 & 액티비티
    "운동", "헬스", "요가", "필라테스", "러닝", "등산", "산책", "클라이밍",
    "축구", "농구", "야구", "배드민턴", "볼링", "수영", "다이어트",
    
    # ❤️ 연애 & 성향
    "연애", "데이트", "소통", "MBTI", "감성", "힐링", "유머", "긍정적", "배려",
    "집순이", "집돌이", "밖순이", "인싸", "대화", 
    
    # 🎵 음악 & 예술
    "음악", "노래방", "악기연주", "콘서트", "페스티벌", "힙합", "K-POP", "발라드", "재즈", "밴드",
    
    # ✈️ 여행 & 자연
    "여행", "국내여행", "해외여행", "캠핑", "차박", "드라이브", "바다", "산", "호캉스", "피크닉",
    
    # 🍽️ 음식 & 카페
    "맛집탐방", "카페", "커피", "디저트", "빵지순례", "요리", "베이킹", 
    "술", "와인", "칵테일", "치맥", "야식", "매운음식",
    
    # 🐶 반려동물
    "반려동물", "강아지", "고양이", "봉사활동"
]

# 3. 불용어 (버릴 단어들)
STOP_WORDS = {
    '나', '저', '제', '우리', '너', '그', '그녀', '당신', '자기', '자신', '본인',
    '이', '그', '저', '요', '서', '네', '도', '는', '은', '이', '가', '을', '를', '의', '에', '로', 
    '것', '걸', '게', '거', '수', '등', '바', '따름', '뿐', '만큼', '데', '듯', '채', '체', '양',
    '때', '곳', '중', '번', '분', '쪽', '말', '일', '개', '가지', '위', '아래', '앞', '뒤', '옆', '안', '밖',
    '좀', '잘', '막', '함', '음', '오', '아', '휴', '엥', '헐', '와', '자', '즉',
    '그냥', '진짜', '정말', '너무', '아주', '매우', '완전', '특히', '주로', '자주', '가끔', '보통', '대체로', '솔직히',
    '그리고', '그래서', '그러나', '하지만', '그런데', '따라서', '또는', '및',
    '함', '임', '됨', '봄', '감', '둠', '준', '건', '관', '련', '해', '해', '봐',
    '좋아함', '사랑함', '선호함', '즐김', '원함', '싶음', '있는', '없는', '하는', '된',
    '요즘', '요새', '오늘', '내일', '주말', '평일', '시간', '날', '사람', '친구', '남', '녀',
    '관심', '취미', '특기', '성격' # 너무 일반적인 단어 추가 제거
}

def extract_keywords(text):
    print(f"🔍 [AI 분석 시작] 입력된 텍스트: {text}")
    
    # --- 1단계: 명사 추출 (기본) ---
    nouns = okt.nouns(text)
    clean_tags = set()
    
    for noun in nouns:
        if len(noun) < 2: continue 
        if noun in STOP_WORDS: continue
        clean_tags.add(noun)
    
    final_tags = list(clean_tags)

    # --- 2단계: 벡터 유사도 분석 (심화) ---
    try:
        doc_embedding = model.encode(text, convert_to_tensor=True)
        cat_embeddings = model.encode(CATEGORIES, convert_to_tensor=True)
        
        # 문장 vs 카테고리 유사도 계산
        cos_scores = util.pytorch_cos_sim(doc_embedding, cat_embeddings)[0]

        print("📊 카테고리 유사도 분석:")
        for idx, score in enumerate(cos_scores):
            # 유사도 기준 0.38 (너무 낮으면 엉뚱한 게 붙음)
            if score > 0.38: 
                category_name = CATEGORIES[idx]
                print(f"  ✨ AI 발견: 문맥상 '{category_name}' 태그 추가 (유사도: {score:.2f})")
                
                if category_name not in final_tags:
                    final_tags.append(category_name)
                    
    except Exception as e:
        print(f"❌ 벡터 분석 중 오류 발생: {e}")

    return final_tags